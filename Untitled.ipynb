{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handmade-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  2026\n",
      "Valid:  506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [02:23<00:00, 14.14it/s]\n",
      "100%|██████████| 506/506 [00:10<00:00, 46.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Doing data augmentation\"\"\"\n",
    "\n",
    "import os #using this library to join this path \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob \n",
    "from tqdm import  tqdm\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "\n",
    "\n",
    "#creating a dir function for checking the path\n",
    "def create_dir(path):\n",
    "    #\"create a directory\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "#function for loading data\n",
    "def load_data(path,split=0.2):\n",
    "    #laod the images and mask\n",
    "    images = sorted(glob(f\"{path}/*/image/*.png\"))\n",
    "    masks  = sorted(glob(f\"{path}/*/mask/*.png\"))\n",
    "    #print(len(images),len(masks))\n",
    "    \"\"\"Splitting the data\"\"\"\n",
    "    split_size=int(len(images)*split)  # how many we want the images we want in validation set\n",
    "    \n",
    "    #random state in train_x and train_y should be same\n",
    "    train_x,valid_x=train_test_split(images,test_size=split_size,random_state=42)\n",
    "    train_y,valid_y=train_test_split(masks ,test_size=split_size,random_state=42)\n",
    "    return (train_x,train_y),(valid_x,valid_y)\n",
    "\n",
    "\n",
    "#Creating augmented funtion\n",
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    \n",
    "    H = 512\n",
    "    W = 512\n",
    "    #\"\"\" Performing data augmentation. \"\"\"\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        dir_name = x.split(\"/\")[-3]  #Extracting Directory name\n",
    "        name = dir_name + \"_\" + x.split(\"/\")[-1].split(\".\")[0]  #now the name of the image is \"folder_name+image_name\"\n",
    "        #\"\"\"Read the image and mask\"\"\"\n",
    "        x= cv2.imread(x,cv2.IMREAD_COLOR)\n",
    "        y= cv2.imread(y,cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment == True:\n",
    "            aug=HorizontalFlip(p=1.0)\n",
    "            augmented=aug(image=x,mask=y)\n",
    "            x1=augmented[\"image\"]\n",
    "            y1=augmented['mask']\n",
    "            \n",
    "            aug=VerticalFlip(p=1)\n",
    "            augmented=aug(image=x,mask=y)\n",
    "            x2=augmented[\"image\"]\n",
    "            y2=augmented['mask']\n",
    "            \n",
    "            aug=Rotate(limit=45,p=1.0)\n",
    "            augmented=aug(image=x,mask=y)\n",
    "            x3=augmented[\"image\"]\n",
    "            y3=augmented['mask']\n",
    "            \n",
    "            #appending the dataset after augmentation\n",
    "            X = [x,x1,x2,x3]\n",
    "            Y = [y,y1,y2,y3]\n",
    "            \n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "            \n",
    "        idx=0\n",
    "        for i, m in zip(X, Y): #i and m are image and mask respectively\n",
    "            #\"\"\"Now resiziing the image and mask\"\"\"\n",
    "            i=cv2.resize(i, (W,H))\n",
    "            m=cv2.resize(m, (W,H))\n",
    "            m=m/255.0\n",
    "            m=(m>0.5)*255  #value in the mask is b/w 0-255\n",
    "            \n",
    "            #saving images and mask  \n",
    "            if len(X)==1:\n",
    "                tmp_image_name = f\"{name}.jpg\"\n",
    "                tmp_mask_name  = f\"{name}.jpg\"\n",
    "            else:\n",
    "                tmp_image_name = f\"{name}_{idx}.jpg\"\n",
    "                tmp_mask_name  = f\"{name}_{idx}.jpg\"\n",
    "                \n",
    "            image_path=os.path.join(save_path,\"image/\",tmp_image_name)\n",
    "            mask_path=os.path.join(save_path,\"mask/\",tmp_mask_name)\n",
    "            cv2.imwrite(image_path,i)\n",
    "            cv2.imwrite(mask_path,m)\n",
    "            idx+=1\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Load the dataset \"\"\"\n",
    "    dataset_path = os.path.join(\"data\", \"train\")\n",
    "    (train_x, train_y), (valid_x, valid_y) = load_data(dataset_path, split=0.2)\n",
    "\n",
    "    print(\"Train: \", len(train_x))\n",
    "    print(\"Valid: \", len(valid_x))\n",
    "\n",
    "    #creating dir for  saving data augumentation data    \n",
    "    create_dir(\"new_data/train/image/\")\n",
    "    create_dir(\"new_data/train/mask/\")\n",
    "    create_dir(\"new_data/valid/image/\")\n",
    "    create_dir(\"new_data/valid/mask/\")\n",
    "\n",
    "    #applying data augmentation(HorizontalFlip, VerticalFlip, Rotate) only in train data \n",
    "    augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
    "    augment_data(valid_x, valid_y, \"new_data/valid/\", augment=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-screw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 128 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 256 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 1024) 4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  2097664     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 512)  2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 524544      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 256 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 256 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 256 590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 256 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 131200      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 128 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 128 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 512, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 512, 512, 1)  65          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# defining model\"\"\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D,Conv2DTranspose, Concatenate,Input\n",
    "from tensorflow.keras.models import  Model\n",
    "\n",
    "#def funtion for Creating convolution block \n",
    "def conv_block(input, num_filters):\n",
    "    x=Conv2D(num_filters,3,padding='same')(input)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    \n",
    "    x=Conv2D(num_filters,3,padding='same')(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "#def fun for encoder_block\n",
    "def encoder_block(input,num_filters):\n",
    "    x=conv_block(input,num_filters)\n",
    "    p=MaxPool2D((2,2))(x)\n",
    "    return x,p  #x act as an skipconnection and p is a output feature for next block\n",
    "\n",
    "def decoder_block(input,skip_features,num_filters):\n",
    "    #applying the transpose conv2d on b1\n",
    "    x=Conv2DTranspose(num_filters,(2,2),strides=2,padding=\"same\")(input)\n",
    "    x=Concatenate()([x,skip_features]) #concatenation skip_connections from previous output and after convolution transpose \n",
    "    x=conv_block(x,num_filters)\n",
    "    return x\n",
    "        \n",
    "    \n",
    "\n",
    "#def fun for building model\n",
    "def unet_model(input_shape):\n",
    "    inputs=Input(input_shape)\n",
    "    \n",
    "    #4 encoder blocks of Unet_model\n",
    "    s1,p1=encoder_block(inputs,64)  #s1,s2,s3,s4 are skip_connection\n",
    "    s2,p2=encoder_block(p1,128)\n",
    "    s3,p3=encoder_block(p2,256)\n",
    "    s4,p4=encoder_block(p3,512)\n",
    "    \n",
    "    #bridge and the bottlneck part of the structure\n",
    "    b1=conv_block(p4,1024)\n",
    "    \n",
    "    #print(s1.shape,s2.shape,s3.shape,s4.shape) chechking for proper skip_connection\n",
    "    d1= decoder_block(b1,s4,512)\n",
    "    d2=decoder_block(d1,s3,256)\n",
    "    d3=decoder_block(d2,s2,128)\n",
    "    d4=decoder_block(d3,s1,64)\n",
    "    \n",
    "    #output layers of 1X1 conv layer with sigmoid fuction\n",
    "    outputs= Conv2D(1,1,padding=\"same\",activation=\"sigmoid\")(d4)\n",
    "    \n",
    "    model=Model(inputs,outputs,name=\"U-net\")\n",
    "    return model\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    input_shape=(512,512,3)\n",
    "    model=unet_model(input_shape)\n",
    "    model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cooked-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chronic-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "def iou(y_true,y_pred):\n",
    "    def f(y_true,y_pred):\n",
    "        intersection=(y_true*y_pred).sum()\n",
    "        union=y_true.sum()+y_pred.sum()-intersection\n",
    "        x=(intersection + 1e-15)/(union+1e-15)\n",
    "        x=x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f,[y_true,y_pred],tf.float32)\n",
    "\n",
    "smooth=1e-15\n",
    "def dice_coef(y_true,y_pred):\n",
    "    y_true=tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred=tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection=tf.reduce_sum(y_true*y_pred)\n",
    "    return (2.* intersection+smooth)/(tf.reduce_sum(y_true)+tf.reduce_sum(y_pred)+smooth)\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "    return 1.0- dice_coef(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quiet-hacker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        #currently, memory growth need to be the same across the gpus\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "        logical_gpus=tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus),\"P`hysical GPUs\",len(logical_gpus),\"logical_gpus\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interim-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wound-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 8104 - 8104\n",
      "train: 506 - 506\n",
      "Epoch 1/16\n",
      "4052/4052 [==============================] - 3146s 776ms/step - loss: 0.6690 - dice_coef: 0.3310 - iou: 0.2500 - recall_1: 0.7935 - precision_1: 0.2752 - val_loss: 0.6667 - val_dice_coef: 0.3333 - val_iou: 0.2842 - val_recall_1: 0.9516 - val_precision_1: 0.3820\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66666, saving model to files/model.h5\n",
      "Epoch 2/16\n",
      "4052/4052 [==============================] - 3143s 776ms/step - loss: 0.4827 - dice_coef: 0.5173 - iou: 0.4594 - recall_1: 0.8596 - precision_1: 0.5496 - val_loss: 0.6516 - val_dice_coef: 0.3484 - val_iou: 0.3090 - val_recall_1: 0.8111 - val_precision_1: 0.8799\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66666 to 0.65158, saving model to files/model.h5\n",
      "Epoch 3/16\n",
      "4052/4052 [==============================] - 3149s 777ms/step - loss: 0.4645 - dice_coef: 0.5355 - iou: 0.4845 - recall_1: 0.8836 - precision_1: 0.5677 - val_loss: 0.6889 - val_dice_coef: 0.3111 - val_iou: 0.2568 - val_recall_1: 0.9640 - val_precision_1: 0.1749\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.65158\n",
      "Epoch 4/16\n",
      "4052/4052 [==============================] - 3145s 776ms/step - loss: 0.4555 - dice_coef: 0.5445 - iou: 0.4970 - recall_1: 0.8944 - precision_1: 0.5785 - val_loss: 0.6501 - val_dice_coef: 0.3499 - val_iou: 0.3064 - val_recall_1: 0.8603 - val_precision_1: 0.6076\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65158 to 0.65015, saving model to files/model.h5\n",
      "Epoch 5/16\n",
      "4052/4052 [==============================] - 3146s 776ms/step - loss: 0.4485 - dice_coef: 0.5515 - iou: 0.5074 - recall_1: 0.9069 - precision_1: 0.5922 - val_loss: 0.6219 - val_dice_coef: 0.3781 - val_iou: 0.3459 - val_recall_1: 0.9214 - val_precision_1: 0.8728\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65015 to 0.62189, saving model to files/model.h5\n",
      "Epoch 6/16\n",
      "4052/4052 [==============================] - 3146s 776ms/step - loss: 0.4451 - dice_coef: 0.5549 - iou: 0.5125 - recall_1: 0.9104 - precision_1: 0.6037 - val_loss: 0.7263 - val_dice_coef: 0.2737 - val_iou: 0.2125 - val_recall_1: 0.8400 - val_precision_1: 0.1341\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.62189\n",
      "Epoch 7/16\n",
      "4052/4052 [==============================] - 3141s 775ms/step - loss: 0.4407 - dice_coef: 0.5593 - iou: 0.5189 - recall_1: 0.9190 - precision_1: 0.6407 - val_loss: 0.6184 - val_dice_coef: 0.3816 - val_iou: 0.3500 - val_recall_1: 0.9382 - val_precision_1: 0.8305\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62189 to 0.61841, saving model to files/model.h5\n",
      "Epoch 8/16\n",
      "4052/4052 [==============================] - 3143s 776ms/step - loss: 0.4377 - dice_coef: 0.5623 - iou: 0.5234 - recall_1: 0.9201 - precision_1: 0.6721 - val_loss: 0.6255 - val_dice_coef: 0.3745 - val_iou: 0.3410 - val_recall_1: 0.9204 - val_precision_1: 0.4796\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61841\n",
      "Epoch 9/16\n",
      "4052/4052 [==============================] - 3147s 777ms/step - loss: 0.4355 - dice_coef: 0.5645 - iou: 0.5268 - recall_1: 0.9243 - precision_1: 0.6637 - val_loss: 0.6187 - val_dice_coef: 0.3813 - val_iou: 0.3495 - val_recall_1: 0.9114 - val_precision_1: 0.8064\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61841\n",
      "Epoch 10/16\n",
      "4052/4052 [==============================] - 3147s 777ms/step - loss: 0.4337 - dice_coef: 0.5663 - iou: 0.5294 - recall_1: 0.9263 - precision_1: 0.6404 - val_loss: 0.6344 - val_dice_coef: 0.3656 - val_iou: 0.3321 - val_recall_1: 0.8944 - val_precision_1: 0.7324\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61841\n",
      "Epoch 11/16\n",
      "4052/4052 [==============================] - 3145s 776ms/step - loss: 0.4320 - dice_coef: 0.5680 - iou: 0.5322 - recall_1: 0.9289 - precision_1: 0.6244 - val_loss: 0.6180 - val_dice_coef: 0.3820 - val_iou: 0.3525 - val_recall_1: 0.9231 - val_precision_1: 0.8245\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61841 to 0.61797, saving model to files/model.h5\n",
      "Epoch 12/16\n",
      "4052/4052 [==============================] - 3145s 776ms/step - loss: 0.4289 - dice_coef: 0.5711 - iou: 0.5370 - recall_1: 0.9334 - precision_1: 0.6154 - val_loss: 0.6520 - val_dice_coef: 0.3480 - val_iou: 0.3063 - val_recall_1: 0.8429 - val_precision_1: 0.3250\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.61797\n",
      "Epoch 13/16\n",
      "4052/4052 [==============================] - 3145s 776ms/step - loss: 0.4271 - dice_coef: 0.5729 - iou: 0.5397 - recall_1: 0.9359 - precision_1: 0.5753 - val_loss: 0.6091 - val_dice_coef: 0.3909 - val_iou: 0.3638 - val_recall_1: 0.9446 - val_precision_1: 0.8771\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.61797 to 0.60915, saving model to files/model.h5\n",
      "Epoch 14/16\n",
      "4052/4052 [==============================] - 3141s 775ms/step - loss: 0.4258 - dice_coef: 0.5742 - iou: 0.5419 - recall_1: 0.9366 - precision_1: 0.5911 - val_loss: 0.6090 - val_dice_coef: 0.3910 - val_iou: 0.3639 - val_recall_1: 0.9490 - val_precision_1: 0.8842\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.60915 to 0.60901, saving model to files/model.h5\n",
      "Epoch 15/16\n",
      "4052/4052 [==============================] - 3138s 774ms/step - loss: 0.4239 - dice_coef: 0.5761 - iou: 0.5449 - recall_1: 0.9400 - precision_1: 0.5719 - val_loss: 0.6256 - val_dice_coef: 0.3744 - val_iou: 0.3407 - val_recall_1: 0.9546 - val_precision_1: 0.6740\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60901\n",
      "Epoch 16/16\n",
      "4052/4052 [==============================] - 3138s 774ms/step - loss: 0.4218 - dice_coef: 0.5782 - iou: 0.5484 - recall_1: 0.9426 - precision_1: 0.5836 - val_loss: 0.6115 - val_dice_coef: 0.3885 - val_iou: 0.3602 - val_recall_1: 0.9317 - val_precision_1: 0.9102\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60901\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training our model on dataset\"\"\"\n",
    "\n",
    "#importing important library\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']=\"2\"\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau,EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import  Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from model import unet_model\n",
    "from metrics import dice_loss, dice_coef, iou\n",
    "\n",
    "H=512\n",
    "W=512\n",
    "#creating a dir function for checking the path\n",
    "def create_dir(path):\n",
    "    #\"create a directory\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def shuffling(x,y):\n",
    "    x,y=shuffle(x,y,random_state=42)\n",
    "    return x,y\n",
    "\n",
    "def load_data(path):\n",
    "    x=sorted(glob(os.path.join(path,\"image\",\"*.jpg\")))\n",
    "    y=sorted(glob(os.path.join(path,\"mask\",\"*.jpg\")))\n",
    "    return x,y\n",
    "\n",
    "#def funtion reading the images\n",
    "def read_image(path):\n",
    "    path= path.decode()\n",
    "    x=cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "    x=x/255.0\n",
    "    x=x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "#def function reading the mask\n",
    "def read_mask(path):\n",
    "    path= path.decode()\n",
    "    x=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    x=x/255.0\n",
    "    x=x>0.5   #threshold for creating image to 0 and 1\n",
    "    x = x.astype(np.float32)\n",
    "    x= np.expand_dims(x,axis=-1)\n",
    "    return x\n",
    "\n",
    "#def tf_parse for building data pipeline\n",
    "def tf_parse(x,y):\n",
    "    def _parse(x,y):\n",
    "        x=read_image(x)\n",
    "        y=read_mask(y)\n",
    "        return x,y\n",
    "    x,y=tf.numpy_function(_parse,[x,y],[tf.float32,tf.float32])  #using tf.numpy_function since we have used cv2.funtion outside the tf \n",
    "    x.set_shape([H,W,3])\n",
    "    y.set_shape([H,W,1])\n",
    "    return x,y\n",
    "\n",
    "\n",
    "#last main function for buuilding data pipeline\n",
    "def tf_dataset(x,y,batch=8):\n",
    "    dataset= tf.data.Dataset.from_tensor_slices((x,y)) #this from_tensor_slices will give individuall image and mask path \n",
    "    dataset= dataset.map(tf_parse)                     #to tf_prarse funtion\n",
    "    dataset= dataset.batch(batch)                      #not it willcreate a batch\n",
    "    dataset= dataset.prefetch(10)                      #it will fetch some of the batch in the memory\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \"\"\"Seeding\"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    \"\"\"creating dir for storing files\"\"\"\n",
    "    create_dir(\"files\")\n",
    "    \n",
    "    \n",
    "    \"\"\"defining Hyperparameter\"\"\"\n",
    "    batch_size=2\n",
    "    lr=1e-4\n",
    "    num_epochs=16\n",
    "    model_path=os.path.join(\"files\",\"model.h5\")\n",
    "    csv_path=os.path.join(\"files\",\"data.csv\")\n",
    "    \n",
    "    \"\"\"Dataset_path\"\"\"\n",
    "    dataset_path=os.path.join(\"new_data\")\n",
    "    train_path=os.path.join(dataset_path,\"train\")\n",
    "    valid_path=os.path.join(dataset_path,\"valid\")\n",
    "    \n",
    "    \n",
    "    train_x,train_y=load_data(train_path) #loading the training data\n",
    "    train_x,train_y=shuffling(train_x,train_y) #shufflnig the traininng data\n",
    "    valid_x,valid_y=load_data(valid_path)\n",
    "    \n",
    "    print(\"train:\",len(train_x),\"-\",len(train_y))\n",
    "    print(\"train:\",len(valid_x),\"-\",len(valid_y))\n",
    "    \n",
    "    train_dataset= tf_dataset(train_x,train_y,batch=batch_size)\n",
    "    valid_dataset= tf_dataset(valid_x,valid_y,batch=batch_size)\n",
    "    \n",
    "    #building the model\n",
    "    model=unet_model((H,W,3))\n",
    "    metrics=[dice_coef,iou,Recall(),Precision()]\n",
    "    model.compile(loss=dice_loss,optimizer=Adam(lr), metrics=metrics )\n",
    "    \n",
    "    \n",
    "    callbacks=[\n",
    "        ModelCheckpoint(model_path,verbose=1,save_best_only=True),  #for saving model weight file\n",
    "        ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=10,min_lr=1e-7,verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        TensorBoard(),\n",
    "        EarlyStopping(monitor='val_loss',patience=50,restore_best_weights=False)\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    model.fit(\n",
    "         train_dataset,\n",
    "         epochs=num_epochs,\n",
    "         validation_data=valid_dataset,\n",
    "         callbacks=callbacks,\n",
    "         shuffle=False\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-newport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "divine-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 506-506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [03:34<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.99440\n",
      "F1:0.80522\n",
      "Jaccard:0.78429\n",
      "Recall:0.97783\n",
      "Precision:0.80418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import  accuracy_score, f1_score, jaccard_score, precision_score,recall_score\n",
    "from metrics import dice_loss, dice_coef, iou\n",
    "from train import  load_data\n",
    "\n",
    "H=512\n",
    "W=512\n",
    "\n",
    "#creating directory\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def save_results(image,mask,y_pred,save_image_path):\n",
    "    line= np.ones((H,10,3))*128\n",
    "    \n",
    "    \"\"\"expanding dimension for Mask\"\"\"\n",
    "    mask= np.expand_dims(mask,axis=-1)  #now the size will be (512,512,1)\n",
    "    mask=np.concatenate([mask,mask,mask],axis=-1) #concating 3 times bcz our image is in 3-dim sonow maskshape is (512,512,3)\n",
    "                                                # now the image and mask and pred_mask are in same size and we can concatenate the easily\n",
    "    \n",
    "    \"\"\"expanding dimension for PredMask\"\"\"\n",
    "    y_pred= np.expand_dims(y_pred,axis=-1)  #now the size will be (512,512,1)\n",
    "    y_pred=np.concatenate([y_pred,y_pred,y_pred],axis=-1) #concating 3 times bcz our image is in 3-dim sonow maskshape is (512,512,3)\n",
    "    y_pred=y_pred*255\n",
    "    \n",
    "    \"\"\"conacting image mask and pred_mask\"\"\"\n",
    "    concatenate_images=np.concatenate([image,line,mask,line,y_pred],axis=1)\n",
    "    cv2.imwrite(save_image_path,concatenate_images)\n",
    "    \n",
    "\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    \"\"\"Seeding\"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    \"\"\"Directory for storing files\"\"\"\n",
    "    create_dir(\"results\")\n",
    "    \n",
    "    \"\"\"Loading model\"\"\"\n",
    "    with CustomObjectScope({'iou': iou, 'dice_coef':dice_coef, \"dice_loss\": dice_loss}):\n",
    "        model=tf.keras.models.load_model(\"files/model.h5\")\n",
    "        #model.summary()\n",
    "    \n",
    "    \"\"\"Load the dataset\"\"\"\n",
    "    test_x=sorted(glob(os.path.join(\"new_data\",\"valid\",\"image\",\"*\")))\n",
    "    test_y=sorted(glob(os.path.join(\"new_data\",\"valid\",\"mask\",\"*\")))\n",
    "    print(f\"Test: {len(test_x)}-{len(test_y)}\")\n",
    "    \n",
    "    \"\"\"Evaluation and prediction \"\"\"\n",
    "    Scores=[]\n",
    "    for x,y in tqdm(zip(test_x,test_y),total=len(test_x)):\n",
    "        \"\"\"Extract the name\"\"\"\n",
    "        name=x.split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        \"reading the image\"\n",
    "        image=cv2.imread(x,cv2.IMREAD_COLOR)\n",
    "        x=image/255.0\n",
    "        x=np.expand_dims(x,axis=0)\n",
    "        \n",
    "        \"\"\"Reading the mask\"\"\"\n",
    "        mask=cv2.imread(y,cv2.IMREAD_GRAYSCALE)\n",
    "        y= mask/255.0\n",
    "        y=y>0.5\n",
    "        y=y.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        \"\"\"Know doingPredicting\"\"\"\n",
    "        y_pred=model.predict(x)[0]   #model will take \"x\" bcz it is the batch size of 1  \n",
    "        y_pred=np.squeeze(y_pred,axis=-1) #it will sequeeze on the last axis and it will ocnverted into H,W of 512 ,512\n",
    "        y_pred= y_pred>0.5\n",
    "        y_pred=y_pred.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        \"\"\" savning the Prediction\"\"\"\n",
    "        save_image_path=f\"results/{name}.png\"\n",
    "        save_results(image,mask,y_pred,save_image_path) #saveresuts take 4 thing: \"origna_image\",\"original_maks\", \"predict_mask\", \"save_path\"\n",
    "        \n",
    "            \n",
    "        #Now working on metrics\n",
    "        \"\"\"Flatten the array\"\"\"\n",
    "        y=y.flatten()\n",
    "        y_pred=y_pred.flatten()\n",
    "\n",
    "        \"\"\"Calculating the metrics values\"\"\"\n",
    "        acc_value=accuracy_score(y,y_pred)\n",
    "        f1_value=f1_score(y,y_pred,labels=[0,1],average='binary',zero_division=1)\n",
    "        jac_vaue=jaccard_score(y,y_pred,labels=[0,1],average='binary',zero_division=1)\n",
    "        recall_value= recall_score(y,y_pred,labels=[0,1],average='binary',zero_division=1)\n",
    "        precision_value=precision_score(y,y_pred,labels=[0,1],average='binary',zero_division=1)\n",
    "        Scores.append([name,acc_value,f1_value,jac_vaue,recall_value,precision_value])\n",
    "        \n",
    "    \n",
    "    \"\"\"Meterics value\"\"\"\n",
    "    score=[s[1:]for s in Scores]\n",
    "    score= np.mean(score,axis=0)\n",
    "    print(f\"Accuracy:{score[0]:0.5f}\")\n",
    "    print(f\"F1:{score[1]:0.5f}\")\n",
    "    print(f\"Jaccard:{score[2]:0.5f}\")\n",
    "    print(f\"Recall:{score[3]:0.5f}\")\n",
    "    print(f\"Precision:{score[4]:0.5f}\")\n",
    "\n",
    "    \n",
    "\n",
    "    df=pd.DataFrame(Scores,columns=[\"Image\",\"Accuracy\",\"F1\", \"Jaccard\",\"Recall\",\"Precision\"])\n",
    "    df.to_csv(\"files/score.csv\")\n",
    "        \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-skating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "weekly-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/832 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 510 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbebc1c4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832/832 [02:21<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom as dicom\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import  accuracy_score, f1_score, jaccard_score, precision_score,recall_score\n",
    "from metrics import dice_loss, dice_coef, iou\n",
    "\n",
    "#creating directory\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    \"\"\"Seeding\"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    \"\"\"Directory for storing files\"\"\"\n",
    "    create_dir(\"tests_result\")\n",
    "    \n",
    "    \"\"\"Loading model\"\"\"\n",
    "    with CustomObjectScope({'iou': iou, 'dice_coef':dice_coef, \"dice_loss\": dice_loss}):\n",
    "        model=tf.keras.models.load_model(\"files/model.h5\")\n",
    "        #model.summary()\n",
    "\n",
    "    \"\"\"Load the test dataset\"\"\"\n",
    "    test_x=glob(\"data/test/*/*/*.dcm\")\n",
    "    print(\"testdata:\",len(test_x))\n",
    "    \n",
    "    \n",
    "    \"\"\"Loop over the data\"\"\"\n",
    "    for x in tqdm(test_x):\n",
    "        \"\"\"Extract the names\"\"\"\n",
    "        dir_names=x.split(\"/\")[-3]\n",
    "        name=dir_names+\"_\"+x.split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        \"\"\"Read the .dcm images\"\"\"\n",
    "        images=dicom.dcmread(x).pixel_array\n",
    "        #print(np.max(image))  #max pixel value is 2000 \n",
    "        \n",
    "        \"\"\"Convertion the image  pixel b/t 0-255\"\"\"\n",
    "        image=np.expand_dims(images,axis=-1)\n",
    "        image=image/np.max(image)*255.0\n",
    "        x=image/255.0   #since model the image btw 0 and 1\n",
    "        x=np.concatenate([x,x,x],axis=-1)\n",
    "        x=np.expand_dims(x,axis=0)\n",
    "        \n",
    "        \n",
    "        \"\"\"Doing prediction on test data \"\"\"\n",
    "        mask=model.predict(x)[0]\n",
    "        mask=mask>0.5\n",
    "        mask=mask.astype(np.int32)\n",
    "        mask=mask*255\n",
    "        \"\"\"conacting image mask and pred_mask\"\"\"\n",
    "        concatenate_images=np.concatenate([image,mask],axis=1)\n",
    "        cv2.imwrite(f\"tests_result/{name}.png\",concatenate_images)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-apparatus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
